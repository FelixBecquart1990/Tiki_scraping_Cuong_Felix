{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ykrd9P6j4qf3"
   },
   "source": [
    "# Week 2 - Connect Tiki Scraper to PostgreSQL database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iSyvsQcW1PR2"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "PostgreSQL is a free and open-source relational database management system. Using a database instead of regular spreadsheet will allow us to store a larger amount of data as well as offer a much higher capacity to later process our data. \n",
    "\n",
    "Instead of exporting the scraped data to a dataframe like we did in Week 1, this time we will push our data to a PostgreSQL database. \n",
    "\n",
    "PostgreSQL databases run locally and therefore each of us will need to install and create our own PostgreSQL database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3KKtbKLi1PR3"
   },
   "source": [
    "# Your tasks: Replace \"__\" with the correct code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6aZ2RM0b1PR4"
   },
   "source": [
    "## Update the Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BKseICjY1PR5"
   },
   "source": [
    "Besides `pandas`, `requests` and `BeautifulSoup`, we will be using another library called `psycopg2` to interact with our PostgreSQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZBDn-lyY4qf9"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "import psycopg2\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NiwLu0ZA1PR8"
   },
   "outputs": [],
   "source": [
    "# Parser function to retrieve and parse the HTML code of a website \n",
    "def parser(url):\n",
    "    \n",
    "    # Plain HTML code\n",
    "    plain = requests.get(url).text\n",
    "    \n",
    "    # Parser\n",
    "    s = BeautifulSoup(plain, \"html.parser\")\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-76H6_094qgI"
   },
   "outputs": [],
   "source": [
    "# Function to get all URLs of categories on Tiki\n",
    "def get_urls():\n",
    "    \n",
    "    url = 'https://tiki.vn/'\n",
    "          \n",
    "    # Run Parser on Tiki\n",
    "    s = parser(url)\n",
    "    \n",
    "    # Initialize an empty list of category \n",
    "    category_list = []\n",
    "\n",
    "    # Scrape\n",
    "    # through the navigator bar on Tiki homepage\n",
    "    for i in s.findAll('a',{'class':'MenuItem__MenuLink-tii3xq-1 efuIbv'}):\n",
    "        \n",
    "        # Get the category value\n",
    "        category = i.find('span',{'class':'text'}).text \n",
    "        \n",
    "        # Get the url value\n",
    "        url = i['href'] + \"&page=1\"\n",
    "        \n",
    "        # Add category and url values to list\n",
    "        category_list.append((category, url))  \n",
    "    # print(category_list)\n",
    "    return category_list\n",
    "# get_urls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b1BCq9BG1PSA"
   },
   "source": [
    "## Connect to PostgreSQL Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0uSPZwd71PSA"
   },
   "source": [
    "The function `get_connection()` creates a connection to our local PostgreSQL database. \n",
    "\n",
    "Change the arguments of `psycopg2.connect()` with your information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DXEpbDwe1PSB"
   },
   "outputs": [],
   "source": [
    "# Function to create connection to our PostgreSQL database\n",
    "def get_connection():\n",
    "    connection = psycopg2.connect(user = \"felix\",\n",
    "                                  password = 'felixpostgre',\n",
    "                                  host = \"127.0.0.1\",\n",
    "                                  port = \"5432\",\n",
    "                                  database = \"mariana\")\n",
    "    return connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jdNsDGEM1PSD"
   },
   "source": [
    "### _Test the function_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352
    },
    "colab_type": "code",
    "id": "e_z0UrPo1PSD",
    "outputId": "5226dcb9-c81c-4ff5-85fa-3a8f92d24e9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<connection object at 0x00000210E51D78C8; dsn: 'user=felix password=xxx dbname=mariana host=127.0.0.1 port=5432', closed: 0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gwbH9tIm1PSF"
   },
   "source": [
    "## Create new table in PostgreSQL Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tQDFHnQB1PSG"
   },
   "source": [
    "`create_products_table()` creates an empty table in our local PostgreSQL database with predefined columns:\n",
    "* product_id: varchar (20)\n",
    "* product_seller_id: varchar (20)\n",
    "* title: text\n",
    "* price: integer\n",
    "* img_url: text\n",
    "* category: text\n",
    "\n",
    "The `cursor` allows Python code to execute PostgreSQL command during our session (connection). `cursor` is always bound to our `connection`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d8ZV4nNH1PSG"
   },
   "outputs": [],
   "source": [
    "# Function to create an empty `products` table in our database if it doesn't exist yet\n",
    "def create_products_table():\n",
    "    \n",
    "    print('INFO create_products_table(): Create table products')\n",
    "    \n",
    "    try:\n",
    "        # Create connection & cursor\n",
    "        connection = __\n",
    "        cursor = __\n",
    "        \n",
    "        # Execute the query\n",
    "        cursor.execute(__)\n",
    "        \n",
    "        # Commit the changes made to our database\n",
    "        connection.__\n",
    "\n",
    "    except (Exception, psycopg2.Error) as error :\n",
    "        print (\"ERROR create_products_table(): Error while connecting to PostgreSQL\", error)\n",
    "        \n",
    "        # In case of error, cancel all changes made to our database during the connection\n",
    "        connection.__\n",
    "        return\n",
    "    \n",
    "    finally:\n",
    "    \n",
    "        # Close the connection & cursor\n",
    "        cursor.__\n",
    "        connection.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hHeZFYWF1PSI"
   },
   "source": [
    "### _Test the function_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qU94fMP_1PSJ"
   },
   "outputs": [],
   "source": [
    "create_products_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qomYcGNK1PSK"
   },
   "source": [
    "## Insert data to PostSQL Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q1iinwfy1PSL"
   },
   "source": [
    "`insert_data_to_db` function inserts the data row into our PostgreSQL table. It takes two arguments: `data` being the results the scrape() function and `table_name` being the table in our database that we want to insert `data` to.\n",
    "\n",
    "This function replaces the step in `scrape_all()` where we add the result of `scrape(cat, url)` to `results`. See changes in funciton `scrape_all()` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Mpm6rfN1PSL"
   },
   "outputs": [],
   "source": [
    "# Function to insert new data to our table\n",
    "def insert_data_to_db(data, table_name):\n",
    "    \n",
    "    print('INFO insert_data_to_db(): Insert data to DB')\n",
    "    \n",
    "    try:\n",
    "        # Create connection & cursor \n",
    "        connection = __\n",
    "        cursor = __\n",
    "        \n",
    "        # For each row (product) in data (product page),...\n",
    "        for row in data:\n",
    "            # Create the query to insert product information to 'table_name'\n",
    "            query = __\n",
    "            \n",
    "            # Execute the query\n",
    "            cursor.execute(__)\n",
    "            \n",
    "            # Commit the changes made to our database\n",
    "            connection.__\n",
    "\n",
    "    except (Exception, psycopg2.Error) as error :\n",
    "        print (\"ERROR save_data_to_db(): Error while connecting to PostgreSQL\", error)\n",
    "        \n",
    "        # In case of error, cancel all changes made to our database during the connection\n",
    "        connection.__\n",
    "        \n",
    "    finally:\n",
    "        \n",
    "        # Close the connection & cursor\n",
    "        cursor.__\n",
    "        connection.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uVrDyACi1PSN"
   },
   "source": [
    "To check if we have successfully created table `products`, go to your terminal, connect to your PostgreSQL database `psql -U [user_name] tiki` then enter `\\d products`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FODiC5ax1PSO"
   },
   "source": [
    "`select_data_from_db()` will get all the data from table `products` to help us see if your scraper works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3hT0Ju831PSO"
   },
   "outputs": [],
   "source": [
    "# Function to get all data from table 'products'\n",
    "def select_data_from_db():\n",
    "    \n",
    "    try:\n",
    "        # Create connection & cursor \n",
    "        connection = __\n",
    "        cursor = __\n",
    "        \n",
    "        # Get all data from table 'products'\n",
    "        cursor.execute(__)      \n",
    "        \n",
    "        # Fetch (Collect) the data and save them in 'data'\n",
    "        data = cursor.__\n",
    "        \n",
    "        return data\n",
    "\n",
    "    except (Exception, psycopg2.Error) as error :\n",
    "        print (\"ERROR save_data_to_db(): Error while connecting to PostgreSQL\", error)\n",
    "        \n",
    "        # In case of error, cancel all changes made to our database during the connection\n",
    "        connection.__\n",
    "        \n",
    "    finally:\n",
    "        \n",
    "        # Close the connection & cursor\n",
    "        cursor.__\n",
    "        connection.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qcnAYbjn1PSQ"
   },
   "source": [
    "The `scrape(cat, url)` function is the same as the one we created in Week 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "atWTPwA-4qhO"
   },
   "outputs": [],
   "source": [
    "# Web scrape function\n",
    "def scrape(cat, url):\n",
    "    \n",
    "    # Initialize empty 'results' list\n",
    "    results = []\n",
    "   \n",
    "    # Run Parser on the product page\n",
    "    s = parser(url)\n",
    "    \n",
    "    # Find all tags <div class='product-item'> and store them in 'prodct_items' list, each tag represent a product\n",
    "    product_items = s.findAll('div',{'class':'product-item'})\n",
    "    \n",
    "    # If the tag list is empty (i.e. the page doesn't have any product), return an empty list.\n",
    "    if len(product_items) == 0:\n",
    "      return []\n",
    "\n",
    "    # If the tag list is not empty (i.e. the page has products),...\n",
    "    else: \n",
    "        \n",
    "        # Iterate through all product and store the product information in the 'row' list\n",
    "        for i in range(len(product_items)):\n",
    "\n",
    "            row = [product_items[i]['data-id'], \n",
    "                   product_items[i]['data-seller-product-id'], \n",
    "                   product_items[i]['data-title'],\n",
    "                   product_items[i]['data-price'], \n",
    "                   product_items[i].find('img',{'class':'product-image img-responsive'})['src'], \n",
    "                   cat]   \n",
    "\n",
    "            # Add the product information of each product into 'results' list\n",
    "            results.append(row)\n",
    "            \n",
    "    # Return the list `results`   \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kbRsfUIR1PST"
   },
   "source": [
    "There are a few changes we will make to our `scrape_all()` function:\n",
    "* Instead of initializing an empty `results` list, we will first run `create_products_table()` to create the `products` table in our database if it doesn't exist yet.\n",
    "* Instead of add the result of `scrape(cat, url)` to `results`, we will add it directly to our table using `insert_data_to_db(data, table_name)`\n",
    "* Since we have already inserted data to the `products` table while the function runs, we won't need to return the list `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4V0dATjR1PST"
   },
   "outputs": [],
   "source": [
    "# Run scrape fuction on every page\n",
    "\n",
    "def scrape_all():\n",
    "    print('INFO scrape_all(): Start scraping')\n",
    "    \n",
    "    # Initialize 'queue' list with the results of get_urls()\n",
    "    queue = __\n",
    "    \n",
    "    # Create table `products` if it doesn't exist yet\n",
    "    # results = []  <-- This is what we did in the first week\n",
    "    __\n",
    "    \n",
    "    # While there are items in `queue`,...\n",
    "    while __:\n",
    "        \n",
    "      # `url` is set to the url of last item in `queue`\n",
    "      url = __\n",
    "      \n",
    "      # `cat` is set to the category of last item in `queue`\n",
    "      cat =__\n",
    "    \n",
    "      # Remove the last item in queue\n",
    "      queue = __\n",
    "\n",
    "      print('Scraping', cat)\n",
    "\n",
    "      # Run scrape(cat, url) with given `cat` and `url`\n",
    "      new_rows = __\n",
    "\n",
    "      # If the result of scrape(cat, url) is not an empty list (i.e. the page has products),...  \n",
    "      if __:\n",
    "        \n",
    "        # Insert the result of scrape(cat, url) to table `product`\n",
    "        # results += new_rows  <-- This is what we did in the first week\n",
    "        __\n",
    "        \n",
    "        # Generate next page url \n",
    "        page = __\n",
    "        url = __\n",
    "        \n",
    "        # Use this to limit our scraper to scrape only the first 10 pages of each category\n",
    "        # We do this to test our scraper with a smaller task first before running through every product page\n",
    "        if page < 10:\n",
    "            \n",
    "            # Add the new page url to the end of list `queue`\n",
    "            queue.__\n",
    "            \n",
    "        print('Add next page', page)\n",
    "    \n",
    "    print('Task completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4eTNSAoG1PSV"
   },
   "source": [
    "### _Test the function_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pCDwQNup1PSV"
   },
   "outputs": [],
   "source": [
    "scrape_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vuWwiNim1PSX"
   },
   "source": [
    "### _Test the results by getting all data in table `products` and put them in a `pandas` dataframe_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wZt2ufSS1PSY"
   },
   "outputs": [],
   "source": [
    "data = select_data_from_db()\n",
    "df = pd.DataFrame(data, columns = ['product_id', 'seller_id', 'title', 'price', 'image_url', 'category'])\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GwXRN8OR1PSZ"
   },
   "source": [
    "Alternatively, you can connect to your PostgreSQL database `psql -U [user_name] tiki` and run query `SELECT * FROM products;`"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copie de ML2-4-Connect Tiki Scraper to PostgreSQL.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
